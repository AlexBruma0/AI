# AI FINAL PROJECT

For our neural network, we decided to start with the provided L-layer network code and customize it to have the best performance for our dataset. Our binary classification neural network was built to recognize whether a human face was generated by AI or if it was an actual human face. Therefore, our dataset consists of images of real faces and images of AI-generated faces.

Initially, we could only find a dataset of roughly 150 AI faces and used a set of 150 real faces. So we were not working with a large dataset; therefore, mini-batching for our case was not necessary. However, since we had such a small dataset, our biggest hurdle would be dealing with variance. From the very start, our bias was very low, with the training set accuracy at approximately 98%. However, our test set accuracy was only hovering around 85%. So we had two strategies for dealing with high variance: the first was to add more training data. Since we could not find more data online useful for this network, we augmented some data, increasing our training set size from 300 images to approximately 400. This was very helpful, bringing our test set accuracy up to 90%. Then we added L2 regularization to improve performance more, which brought our test accuracy up to 93.3%.

We also worked on tuning the hyperparameters to improve performance. The first thing we did was to increase the number of epochs. This brought our training set accuracy up to 99.4%. Other hyperparameters we tuned were Lambda for L2 regularization and the learning rate. In a perfect world, we would have preferred to try 25 random values of each hyperparameter. However, training our network took about roughly 8-10 minutes. Therefore, trying 25 different values for lambda and our learning rate was just not possible with our resources. As seen above in the graph, we saw that 0.0075 for our learning rate had the best performance. And 0.01 for lambda also performed the best. We tested five values for the learning rate and five for lambda.

In conclusion, our biggest hurdle was dealing with our small training set. We really loved the idea of this network, so we decided to make it work as best as we could. To deal with variance, we augmented data and used L2 regularization. We also optimized different hyperparameters to get the best performance we could. In an ideal world, we would have preferred to try more values for our hyperparameters. Unfortunately, our computers would not be able to handle it. Nevertheless, after all our optimizations, our training set accuracy is 99.4% (started at 98%), and test set accuracy is 93.33% (started at 85%). This is not an optimal result, but one we are willing to accept nonetheless.
